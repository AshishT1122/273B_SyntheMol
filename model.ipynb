{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import DataLoader, Batch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('model_data.csv')\n",
    "\n",
    "graphs = []\n",
    "labels = []\n",
    "\n",
    "def get_atom_features(mol):\n",
    "    features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        aromatic = atom.GetIsAromatic()\n",
    "        chirality = atom.GetChiralTag()\n",
    "        formal_charge = atom.GetFormalCharge()\n",
    "        num_hydrogens = atom.GetTotalNumHs()\n",
    "        num_valence = atom.GetTotalValence()\n",
    "        hybridization = atom.GetHybridization()\n",
    "        is_in_ring = atom.IsInRing()\n",
    "\n",
    "        hybridization = {\n",
    "            Chem.rdchem.HybridizationType.SP: 1,\n",
    "            Chem.rdchem.HybridizationType.SP2: 2,\n",
    "            Chem.rdchem.HybridizationType.SP3: 3,\n",
    "            Chem.rdchem.HybridizationType.SP3D: 4,\n",
    "            Chem.rdchem.HybridizationType.SP3D2: 5,\n",
    "            Chem.rdchem.HybridizationType.UNSPECIFIED: 0\n",
    "        }.get(hybridization, 0)\n",
    "        \n",
    "        feature_vector = [\n",
    "            atomic_num,\n",
    "            int(aromatic),\n",
    "            int(chirality != Chem.ChiralType.CHI_UNSPECIFIED),\n",
    "            formal_charge,\n",
    "            num_hydrogens,\n",
    "            num_valence,\n",
    "            hybridization,\n",
    "            int(is_in_ring)\n",
    "        ]\n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def molecule_to_graph(mol):\n",
    "    bonds = mol.GetBonds()\n",
    "    \n",
    "    node_features = get_atom_features(mol)\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "\n",
    "    for bond in bonds:\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index.append((start, end))\n",
    "        edge_index.append((end, start))\n",
    "        edge_features += [bond.GetBondTypeAsDouble(), bond.GetBondTypeAsDouble()]\n",
    "\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mol = Chem.MolFromMolFile(f\"diffdock_chembl_output/diffdock_chembl_output/{row['Molecule ChEMBL ID']}/{row['Filepath']}\")\n",
    "    graphs.append(molecule_to_graph(mol))\n",
    "    labels.append(1 if row['Comment'] == 'active' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 1)\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.pool(x, batch)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "count_active = sum(1 for label in labels if label == 1)\n",
    "count_inactive = len(labels) - count_active\n",
    "difference = count_inactive - count_active\n",
    "\n",
    "active_indices = [i for i, label in enumerate(labels) if label == 1]\n",
    "additional_indices = np.random.choice(active_indices, difference)\n",
    "\n",
    "graphs_resampled = graphs + [graphs[i] for i in additional_indices]\n",
    "labels_resampled = labels + [labels[i] for i in additional_indices]\n",
    "\n",
    "combined = list(zip(graphs_resampled, labels_resampled))\n",
    "random.shuffle(combined)\n",
    "graphs_resampled, labels_resampled = zip(*combined)\n",
    "\n",
    "split_size = int(0.8 * len(graphs_resampled))\n",
    "train_data = combined[:split_size]\n",
    "val_data = combined[split_size:]\n",
    "\n",
    "model = GCN(num_features=8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I587597/Documents/SyntheMol/.venv/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.7078, Val Loss: 0.6963, Val Accuracy: 0.4943\n",
      "Epoch: 2, Train Loss: 0.6917, Val Loss: 0.6892, Val Accuracy: 0.5634\n",
      "Epoch: 3, Train Loss: 0.6907, Val Loss: 0.6867, Val Accuracy: 0.5469\n",
      "Epoch: 4, Train Loss: 0.6888, Val Loss: 0.6834, Val Accuracy: 0.5761\n",
      "Epoch: 5, Train Loss: 0.6866, Val Loss: 0.6828, Val Accuracy: 0.5544\n",
      "Epoch: 6, Train Loss: 0.6860, Val Loss: 0.6796, Val Accuracy: 0.5750\n",
      "Epoch: 7, Train Loss: 0.6853, Val Loss: 0.6801, Val Accuracy: 0.5719\n",
      "Epoch: 8, Train Loss: 0.6848, Val Loss: 0.6797, Val Accuracy: 0.5751\n",
      "Epoch: 9, Train Loss: 0.6852, Val Loss: 0.6813, Val Accuracy: 0.5821\n",
      "Epoch: 10, Train Loss: 0.6842, Val Loss: 0.6787, Val Accuracy: 0.5720\n",
      "Epoch: 11, Train Loss: 0.6840, Val Loss: 0.6776, Val Accuracy: 0.5842\n",
      "Epoch: 12, Train Loss: 0.6840, Val Loss: 0.6792, Val Accuracy: 0.5733\n",
      "Epoch: 13, Train Loss: 0.6835, Val Loss: 0.6804, Val Accuracy: 0.5740\n",
      "Epoch: 14, Train Loss: 0.6845, Val Loss: 0.6783, Val Accuracy: 0.5767\n",
      "Epoch: 15, Train Loss: 0.6829, Val Loss: 0.6794, Val Accuracy: 0.5732\n",
      "Epoch: 16, Train Loss: 0.6841, Val Loss: 0.6764, Val Accuracy: 0.5856\n",
      "Epoch: 17, Train Loss: 0.6840, Val Loss: 0.6852, Val Accuracy: 0.5448\n",
      "Epoch: 18, Train Loss: 0.6821, Val Loss: 0.6781, Val Accuracy: 0.5754\n",
      "Epoch: 19, Train Loss: 0.6834, Val Loss: 0.6760, Val Accuracy: 0.5876\n",
      "Epoch: 20, Train Loss: 0.6841, Val Loss: 0.6766, Val Accuracy: 0.5854\n",
      "Epoch: 21, Train Loss: 0.6836, Val Loss: 0.6757, Val Accuracy: 0.5832\n",
      "Epoch: 22, Train Loss: 0.6839, Val Loss: 0.6778, Val Accuracy: 0.5881\n",
      "Epoch: 23, Train Loss: 0.6843, Val Loss: 0.6799, Val Accuracy: 0.5667\n",
      "Epoch: 24, Train Loss: 0.6842, Val Loss: 0.6766, Val Accuracy: 0.5876\n",
      "Epoch: 25, Train Loss: 0.6834, Val Loss: 0.6769, Val Accuracy: 0.5873\n",
      "Epoch: 26, Train Loss: 0.6828, Val Loss: 0.6773, Val Accuracy: 0.5734\n",
      "Epoch: 27, Train Loss: 0.6828, Val Loss: 0.6760, Val Accuracy: 0.5892\n",
      "Epoch: 28, Train Loss: 0.6832, Val Loss: 0.6763, Val Accuracy: 0.5891\n",
      "Epoch: 29, Train Loss: 0.6832, Val Loss: 0.6785, Val Accuracy: 0.5688\n",
      "Epoch: 30, Train Loss: 0.6836, Val Loss: 0.6787, Val Accuracy: 0.5771\n",
      "Epoch: 31, Train Loss: 0.6828, Val Loss: 0.6742, Val Accuracy: 0.5894\n",
      "Epoch: 32, Train Loss: 0.6840, Val Loss: 0.6761, Val Accuracy: 0.5867\n",
      "Epoch: 33, Train Loss: 0.6835, Val Loss: 0.6760, Val Accuracy: 0.5883\n",
      "Epoch: 34, Train Loss: 0.6837, Val Loss: 0.6748, Val Accuracy: 0.5916\n",
      "Epoch: 35, Train Loss: 0.6835, Val Loss: 0.6755, Val Accuracy: 0.5881\n",
      "Epoch: 36, Train Loss: 0.6830, Val Loss: 0.6771, Val Accuracy: 0.5911\n",
      "Epoch: 37, Train Loss: 0.6831, Val Loss: 0.6791, Val Accuracy: 0.5670\n",
      "Epoch: 38, Train Loss: 0.6828, Val Loss: 0.6757, Val Accuracy: 0.5823\n",
      "Epoch: 39, Train Loss: 0.6826, Val Loss: 0.6766, Val Accuracy: 0.5811\n",
      "Epoch: 40, Train Loss: 0.6830, Val Loss: 0.6752, Val Accuracy: 0.5826\n",
      "Epoch: 41, Train Loss: 0.6816, Val Loss: 0.6753, Val Accuracy: 0.5845\n",
      "Epoch: 42, Train Loss: 0.6838, Val Loss: 0.6764, Val Accuracy: 0.5881\n",
      "Epoch: 43, Train Loss: 0.6827, Val Loss: 0.6786, Val Accuracy: 0.5794\n",
      "Epoch: 44, Train Loss: 0.6831, Val Loss: 0.6734, Val Accuracy: 0.5845\n",
      "Epoch: 45, Train Loss: 0.6842, Val Loss: 0.6760, Val Accuracy: 0.5890\n",
      "Epoch: 46, Train Loss: 0.6828, Val Loss: 0.6751, Val Accuracy: 0.5915\n",
      "Epoch: 47, Train Loss: 0.6840, Val Loss: 0.6777, Val Accuracy: 0.5894\n",
      "Epoch: 48, Train Loss: 0.6830, Val Loss: 0.6768, Val Accuracy: 0.5854\n",
      "Epoch: 49, Train Loss: 0.6824, Val Loss: 0.6743, Val Accuracy: 0.5921\n",
      "Epoch: 50, Train Loss: 0.6831, Val Loss: 0.6759, Val Accuracy: 0.5908\n",
      "Epoch: 51, Train Loss: 0.6821, Val Loss: 0.6753, Val Accuracy: 0.5902\n",
      "Epoch: 52, Train Loss: 0.6818, Val Loss: 0.6762, Val Accuracy: 0.5902\n",
      "Epoch: 53, Train Loss: 0.6820, Val Loss: 0.6782, Val Accuracy: 0.5792\n",
      "Epoch: 54, Train Loss: 0.6820, Val Loss: 0.6775, Val Accuracy: 0.5726\n",
      "Epoch: 55, Train Loss: 0.6821, Val Loss: 0.6749, Val Accuracy: 0.5888\n",
      "Epoch: 56, Train Loss: 0.6824, Val Loss: 0.6797, Val Accuracy: 0.5706\n",
      "Epoch: 57, Train Loss: 0.6824, Val Loss: 0.6803, Val Accuracy: 0.5641\n",
      "Epoch: 58, Train Loss: 0.6841, Val Loss: 0.6762, Val Accuracy: 0.5905\n",
      "Epoch: 59, Train Loss: 0.6827, Val Loss: 0.6746, Val Accuracy: 0.5883\n",
      "Epoch: 60, Train Loss: 0.6828, Val Loss: 0.6767, Val Accuracy: 0.5764\n",
      "Epoch: 61, Train Loss: 0.6828, Val Loss: 0.6824, Val Accuracy: 0.5562\n",
      "Epoch: 62, Train Loss: 0.6823, Val Loss: 0.6749, Val Accuracy: 0.5914\n",
      "Epoch: 63, Train Loss: 0.6830, Val Loss: 0.6765, Val Accuracy: 0.5904\n",
      "Epoch: 64, Train Loss: 0.6822, Val Loss: 0.6738, Val Accuracy: 0.5936\n",
      "Epoch: 65, Train Loss: 0.6826, Val Loss: 0.6767, Val Accuracy: 0.5743\n",
      "Epoch: 66, Train Loss: 0.6817, Val Loss: 0.6753, Val Accuracy: 0.5811\n",
      "Epoch: 67, Train Loss: 0.6820, Val Loss: 0.6758, Val Accuracy: 0.5815\n",
      "Epoch: 68, Train Loss: 0.6826, Val Loss: 0.6759, Val Accuracy: 0.5804\n",
      "Epoch: 69, Train Loss: 0.6822, Val Loss: 0.6733, Val Accuracy: 0.5924\n",
      "Epoch: 70, Train Loss: 0.6823, Val Loss: 0.6756, Val Accuracy: 0.5876\n",
      "Epoch: 71, Train Loss: 0.6814, Val Loss: 0.6765, Val Accuracy: 0.5908\n",
      "Epoch: 72, Train Loss: 0.6817, Val Loss: 0.6751, Val Accuracy: 0.5924\n",
      "Epoch: 73, Train Loss: 0.6829, Val Loss: 0.6762, Val Accuracy: 0.5877\n",
      "Epoch: 74, Train Loss: 0.6815, Val Loss: 0.6770, Val Accuracy: 0.5801\n",
      "Epoch: 75, Train Loss: 0.6818, Val Loss: 0.6765, Val Accuracy: 0.5782\n",
      "Epoch: 76, Train Loss: 0.6823, Val Loss: 0.6762, Val Accuracy: 0.5880\n",
      "Epoch: 77, Train Loss: 0.6815, Val Loss: 0.6748, Val Accuracy: 0.5891\n",
      "Epoch: 78, Train Loss: 0.6830, Val Loss: 0.6746, Val Accuracy: 0.5931\n",
      "Epoch: 79, Train Loss: 0.6831, Val Loss: 0.6792, Val Accuracy: 0.5617\n",
      "Epoch: 80, Train Loss: 0.6822, Val Loss: 0.6750, Val Accuracy: 0.5836\n",
      "Epoch: 81, Train Loss: 0.6825, Val Loss: 0.6765, Val Accuracy: 0.5898\n",
      "Epoch: 82, Train Loss: 0.6813, Val Loss: 0.6751, Val Accuracy: 0.5828\n",
      "Epoch: 83, Train Loss: 0.6828, Val Loss: 0.6784, Val Accuracy: 0.5777\n",
      "Epoch: 84, Train Loss: 0.6830, Val Loss: 0.6752, Val Accuracy: 0.5936\n",
      "Epoch: 85, Train Loss: 0.6823, Val Loss: 0.6746, Val Accuracy: 0.5915\n",
      "Epoch: 86, Train Loss: 0.6823, Val Loss: 0.6777, Val Accuracy: 0.5750\n",
      "Epoch: 87, Train Loss: 0.6831, Val Loss: 0.6747, Val Accuracy: 0.5916\n",
      "Epoch: 88, Train Loss: 0.6817, Val Loss: 0.6747, Val Accuracy: 0.5929\n",
      "Epoch: 89, Train Loss: 0.6817, Val Loss: 0.6775, Val Accuracy: 0.5746\n",
      "Epoch: 90, Train Loss: 0.6819, Val Loss: 0.6744, Val Accuracy: 0.5932\n",
      "Epoch: 91, Train Loss: 0.6838, Val Loss: 0.6748, Val Accuracy: 0.5907\n",
      "Epoch: 92, Train Loss: 0.6827, Val Loss: 0.6779, Val Accuracy: 0.5741\n",
      "Epoch: 93, Train Loss: 0.6818, Val Loss: 0.6760, Val Accuracy: 0.5826\n",
      "Epoch: 94, Train Loss: 0.6827, Val Loss: 0.6764, Val Accuracy: 0.5733\n",
      "Epoch: 95, Train Loss: 0.6828, Val Loss: 0.6737, Val Accuracy: 0.5966\n",
      "Epoch: 96, Train Loss: 0.6817, Val Loss: 0.6757, Val Accuracy: 0.5881\n",
      "Epoch: 97, Train Loss: 0.6822, Val Loss: 0.6750, Val Accuracy: 0.5901\n",
      "Epoch: 98, Train Loss: 0.6818, Val Loss: 0.6734, Val Accuracy: 0.5900\n",
      "Epoch: 99, Train Loss: 0.6826, Val Loss: 0.6789, Val Accuracy: 0.5699\n",
      "Epoch: 100, Train Loss: 0.6817, Val Loss: 0.6736, Val Accuracy: 0.5914\n",
      "Validation Loss: 0.6736051837603251\n",
      "Confusion Matrix:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.60      0.50      0.55      3489\n",
      "      Active       0.58      0.68      0.63      3598\n",
      "\n",
      "    accuracy                           0.59      7087\n",
      "   macro avg       0.59      0.59      0.59      7087\n",
      "weighted avg       0.59      0.59      0.59      7087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def collate(data_list):\n",
    "    batch, labels = Batch.from_data_list([data[0] for data in data_list]), torch.tensor([data[1] for data in data_list], dtype=torch.float)\n",
    "    return batch, labels\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False, collate_fn=collate)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch, labels in train_loader:\n",
    "        labels = labels.float()  # Ensure labels are float\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch).squeeze()\n",
    "        loss = loss_func(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in val_loader:\n",
    "            labels = labels.float()  # Ensure labels are float\n",
    "            out = model(batch).squeeze()\n",
    "            loss = loss_func(out, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = (out > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "    \n",
    "    cr = classification_report(all_labels, all_preds, target_names=['Inactive', 'Active'])\n",
    "    return total_loss / len(val_loader), correct / len(val_loader.dataset), cr\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    val_loss, val_acc, cr = validate()\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}')\n",
    "\n",
    "val_loss, val_acc, cr = validate()\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(\"Confusion Matrix:\\n\", cr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels_resampled.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'gcn_model.pth')\n",
    "\n",
    "# Save the graphs and labels (optional, if needed)\n",
    "joblib.dump(graphs_resampled, 'graphs_resampled.pkl')\n",
    "joblib.dump(labels_resampled, 'labels_resampled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful.\n",
      "Response: {'status': 'success'}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:8080/diffdock\"\n",
    "payload = {\n",
    "    \"smiles\": \"CCCCC(NC(=O)CCC(=O)O)P(=O)(O)OC1=CC=CC=C1\"\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.get(url, json=payload)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful.\")\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "    print(\"Response:\", response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
